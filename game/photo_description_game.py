import json
import os
import re
from typing import Dict, List, Tuple
from difflib import SequenceMatcher
import random

# NLP Libraries
try:
    import nltk
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from nltk.stem import WordNetLemmatizer
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    NLP_AVAILABLE = True
except ImportError:
    NLP_AVAILABLE = False
    print("NLP libraries not available. Using basic comparison.")

class PhotoDescriptionGame:
    """
    Sistema de jogo baseado em descri√ß√µes de fotos hist√≥ricas do Recife
    """
    
    def __init__(self):
        self.photos_data = self._load_photos_data()
        self.current_photo = None
        self.game_stats = {
            "total_attempts": 0,
            "total_correct": 0,
            "total_points": 0,
            "current_streak": 0,
            "best_streak": 0
        }
        
        # Inicializar NLP
        if NLP_AVAILABLE:
            self._initialize_nlp()
            self.use_nlp = True
        else:
            self.use_nlp = False
    
    def _initialize_nlp(self):
        """Inicializa recursos do NLTK"""
        try:
            print("\nüöÄ Inicializando NLP...")
            # Download recursos necess√°rios
            nltk.download('punkt', quiet=True)
            nltk.download('stopwords', quiet=True)
            nltk.download('wordnet', quiet=True)
            nltk.download('omw-1.4', quiet=True)
            
            self.stop_words = set(stopwords.words('portuguese'))
            self.lemmatizer = WordNetLemmatizer()
            self.vectorizer = TfidfVectorizer(max_features=1000)
            
            print("‚úÖ NLP inicializado com sucesso!")
            print(f"   - Stopwords carregadas: {len(self.stop_words)} palavras")
            print(f"   - M√©todo de similaridade: TF-IDF + Cosseno")
        except Exception as e:
            print(f"‚ùå Erro ao inicializar NLP: {e}")
            self.use_nlp = False
    
    def _load_photos_data(self) -> List[Dict]:
        """Carrega os dados das fotos hist√≥ricas"""
        try:
            with open('data/photo_descriptions.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print("Arquivo photo_descriptions.json n√£o encontrado!")
            return []
    
    def get_random_photo(self) -> Dict:
        """Retorna uma foto aleat√≥ria para o jogo"""
        if not self.photos_data:
            return None
        
        self.current_photo = random.choice(self.photos_data)
        return {
            "id": self.current_photo["id"],
            "image_path": self.current_photo["image_path"],
            "name": self.current_photo["name"],
            "difficulty": self.current_photo["difficulty"],
            "points": self.current_photo["points"]
        }
    
    def submit_description(self, user_description: str) -> Dict:
        """
        Compara a descri√ß√£o do usu√°rio com a descri√ß√£o oficial
        """
        if not self.current_photo:
            return {"error": "Nenhuma foto selecionada"}
        
        # Limpar e normalizar descri√ß√µes
        user_desc_clean = self._clean_text(user_description)
        official_desc_clean = self._clean_text(self.current_photo["official_description"])
        
        # Processar com NLP se dispon√≠vel
        if self.use_nlp:
            user_desc_processed = self._preprocess_nlp(user_desc_clean)
            official_desc_processed = self._preprocess_nlp(official_desc_clean)
            
            # Debug: mostrar processamento NLP
            print(f"\nüîç [NLP DEBUG]")
            print(f"   Original: {user_desc_clean[:100]}...")
            print(f"   Processado: {user_desc_processed[:100]}...")
        else:
            user_desc_processed = user_desc_clean
            official_desc_processed = official_desc_clean
        
        # Calcular similaridade
        similarity_score = self._calculate_similarity(user_desc_processed, official_desc_processed)
        
        # Verificar palavras-chave
        keyword_score = self._check_keywords(user_desc_clean, self.current_photo["keywords"])
        
        # Calcular pontua√ß√£o final
        final_score = self._calculate_final_score(similarity_score, keyword_score)
        
        # Determinar se acertou (threshold de 60%)
        is_correct = final_score >= 0.6
        
        # Atualizar estat√≠sticas
        self._update_stats(is_correct)
        
        # Calcular pontos ganhos
        points_earned = self._calculate_points(final_score, is_correct)
        
        return {
            "success": True,
            "is_correct": is_correct,
            "similarity_score": similarity_score,
            "keyword_score": keyword_score,
            "final_score": final_score,
            "points_earned": points_earned,
            "official_description": self.current_photo["official_description"],
            "keywords_found": self._get_found_keywords(user_desc_clean, self.current_photo["keywords"]),
            "feedback": self._generate_feedback(final_score, is_correct),
            "game_stats": self.game_stats.copy()
        }
    
    def _clean_text(self, text: str) -> str:
        """Limpa e normaliza texto para compara√ß√£o"""
        # Converter para min√∫sculas
        text = text.lower()
        
        # Remover acentos e caracteres especiais
        text = re.sub(r'[√†√°√¢√£√§√•]', 'a', text)
        text = re.sub(r'[√®√©√™√´]', 'e', text)
        text = re.sub(r'[√¨√≠√Æ√Ø]', 'i', text)
        text = re.sub(r'[√≤√≥√¥√µ√∂]', 'o', text)
        text = re.sub(r'[√π√∫√ª√º]', 'u', text)
        text = re.sub(r'[√ß]', 'c', text)
        
        # Remover pontua√ß√£o e caracteres especiais
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # Remover espa√ßos extras
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _preprocess_nlp(self, text: str) -> str:
        """Processa texto com NLP (tokeniza√ß√£o, lemmatiza√ß√£o, remo√ß√£o de stopwords)"""
        if not self.use_nlp:
            return text
        
        try:
            # Tokenizar
            tokens = word_tokenize(text, language='portuguese')
            
            # Remover stopwords e lemmatizar
            processed_tokens = []
            for token in tokens:
                if token.lower() not in self.stop_words:
                    lemma = self.lemmatizer.lemmatize(token.lower())
                    if len(lemma) > 2:  # Filtrar palavras muito curtas
                        processed_tokens.append(lemma)
            
            return ' '.join(processed_tokens)
        except Exception as e:
            print(f"Erro no preprocessing NLP: {e}")
            return text
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calcula similaridade entre dois textos"""
        if self.use_nlp:
            # Usar TF-IDF + Cosseno para similaridade sem√¢ntica
            try:
                tfidf_matrix = self.vectorizer.fit_transform([text1, text2])
                similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
                return float(similarity)
            except Exception as e:
                print(f"Erro no c√°lculo TF-IDF: {e}")
                # Fallback para SequenceMatcher
                return SequenceMatcher(None, text1, text2).ratio()
        else:
            # Usar SequenceMatcher (b√°sico)
            return SequenceMatcher(None, text1, text2).ratio()
    
    def _check_keywords(self, user_text: str, keywords: List[str]) -> float:
        """Verifica quantas palavras-chave foram encontradas"""
        if not keywords:
            return 0.0
        
        found_keywords = 0
        for keyword in keywords:
            if keyword.lower() in user_text:
                found_keywords += 1
        
        return found_keywords / len(keywords)
    
    def _calculate_final_score(self, similarity: float, keyword_score: float) -> float:
        """Calcula pontua√ß√£o final combinando similaridade e palavras-chave"""
        # Peso: 60% similaridade + 40% palavras-chave
        return (similarity * 0.6) + (keyword_score * 0.4)
    
    def _calculate_points(self, final_score: float, is_correct: bool) -> int:
        """Calcula pontos ganhos baseado na pontua√ß√£o"""
        if not is_correct:
            return 0
        
        base_points = self.current_photo["points"]
        
        # Multiplicador baseado na qualidade da resposta
        if final_score >= 0.9:
            multiplier = 1.5  # Excelente
        elif final_score >= 0.8:
            multiplier = 1.3  # Muito bom
        elif final_score >= 0.7:
            multiplier = 1.1  # Bom
        else:
            multiplier = 1.0  # B√°sico
        
        return int(base_points * multiplier)
    
    def _get_found_keywords(self, user_text: str, keywords: List[str]) -> List[str]:
        """Retorna palavras-chave encontradas na descri√ß√£o do usu√°rio"""
        found = []
        for keyword in keywords:
            if keyword.lower() in user_text:
                found.append(keyword)
        return found
    
    def _generate_feedback(self, final_score: float, is_correct: bool) -> str:
        """Gera feedback baseado na pontua√ß√£o"""
        if final_score >= 0.9:
            return "Excelente! Sua descri√ß√£o capturou muito bem os elementos principais da foto!"
        elif final_score >= 0.8:
            return "Muito bom! Voc√™ identificou corretamente a maioria dos elementos importantes."
        elif final_score >= 0.7:
            return "Bom trabalho! Voc√™ acertou v√°rios aspectos da foto hist√≥rica."
        elif final_score >= 0.6:
            return "Parab√©ns! Voc√™ conseguiu identificar alguns elementos corretos."
        elif final_score >= 0.4:
            return "Continue tentando! Voc√™ est√° no caminho certo, mas pode melhorar."
        else:
            return "N√£o desista! Observe melhor os detalhes da foto e tente novamente."
    
    def _update_stats(self, is_correct: bool):
        """Atualiza estat√≠sticas do jogo"""
        self.game_stats["total_attempts"] += 1
        
        if is_correct:
            self.game_stats["total_correct"] += 1
            self.game_stats["current_streak"] += 1
            self.game_stats["best_streak"] = max(
                self.game_stats["best_streak"], 
                self.game_stats["current_streak"]
            )
        else:
            self.game_stats["current_streak"] = 0
    
    def get_game_stats(self) -> Dict:
        """Retorna estat√≠sticas do jogo"""
        accuracy = 0
        if self.game_stats["total_attempts"] > 0:
            accuracy = self.game_stats["total_correct"] / self.game_stats["total_attempts"]
        
        return {
            **self.game_stats,
            "accuracy": accuracy
        }
    
    def reset_game(self):
        """Reseta o jogo"""
        self.current_photo = None
        self.game_stats = {
            "total_attempts": 0,
            "total_correct": 0,
            "total_points": 0,
            "current_streak": 0,
            "best_streak": 0
        }
    
    def get_photo_by_id(self, photo_id: str) -> Dict:
        """Retorna uma foto espec√≠fica pelo ID"""
        for photo in self.photos_data:
            if photo["id"] == photo_id:
                return photo
        return None

# Exemplo de uso
if __name__ == "__main__":
    game = PhotoDescriptionGame()
    
    # Obter foto aleat√≥ria
    photo = game.get_random_photo()
    print(f"Foto: {photo['name']}")
    print(f"Dificuldade: {photo['difficulty']}")
    
    # Simular descri√ß√£o do usu√°rio
    user_desc = "Esta √© uma pra√ßa hist√≥rica com cal√ßada de pedra portuguesa e vista para o mar"
    result = game.submit_description(user_desc)
    
    print(f"\nResultado:")
    print(f"Acertou: {result['is_correct']}")
    print(f"Pontua√ß√£o: {result['final_score']:.2f}")
    print(f"Pontos ganhos: {result['points_earned']}")
    print(f"Feedback: {result['feedback']}")
